{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRx75YvD3BPW"
   },
   "source": [
    "## <font color = red> *** FILL HERE *** </font>\n",
    "Type your name here <br>\n",
    "Student number <br>\n",
    "Utumail address  <br>\n",
    "Date  <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpio-nMAoDwq"
   },
   "source": [
    "------\n",
    "\n",
    "# Data Analysis and Knowledge Discovery: Exercise 2, Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90c9fF6woDwr"
   },
   "source": [
    "The previous exercise was about <i>data understanding</i> and <i>data preparation</i>, which formed the basis for the modeling phase of the data mining process. Many modeling techniques make assumptions about data so the exploration and preparation phases can't be ignored. Now, as we have checked the validity of data and familiarized ourselves with it, we can move on to the next stage of the Cross-Industry Standard Process for Data Mining (CRISP-DM) which is <font color = darkorchid><i>modeling</i></font>.\n",
    "\n",
    "The questions to be answered at this stage could be for example:\n",
    "\n",
    "- What kind of model architecture best fits our data?\n",
    "- How well does the model perform technically?\n",
    "- Could we improve that performance?\n",
    "- How the performance of the model is evaluated?\n",
    "\n",
    "<i>Machine learning</i> is a subfield of artificial intelligence which provides automatic, objective and data-driven techniques for modeling the data. The machine learning algorithms aim to learn from data to make predictions. The two main branches of it are <i>supervised learning</i> and <i>unsupervised learning</i>.  In this exercise, we are going to use the former -- <font color = darkorchid><i>supervised learning</i></font> -- for classification and regression tasks.\n",
    "\n",
    "For classification, data remains the same as in the previous exercise, but I've already cleaned it up for you. Some data pre-processing steps are still required to ensure that it's in an appropriate format, so that models can learn something from it. Even though we are not doing any major data exploration nor data preparation here this time, <i>you should <b>never</b> forget it in your future data analyses</i>.\n",
    "\n",
    "-----\n",
    "\n",
    "<b>General guidance for exercises</b>\n",
    "\n",
    "- Answer <b>all</b> questions below, even if you can't get your script to fully work.\n",
    "- Write clear and easily readable code, and include explanations what your code does\n",
    "- Make informative illustrations: include labels for x and y axes, legends and captions for your plots.\n",
    "- You can add more code and markup cells, as long as the flow of the notebook stays readable and logical.\n",
    "- Before saving the ipynb file (and possible printing) run: \"Restart & Run all\", to make sure you return a file that works as expected.\n",
    "- Grading: *Fail*/*Pass*/*Pass with honors* (+1)\n",
    "- +1 bonus point (grading *Pass with honors*) requires a <b>completely</b> correct solution and also thorough analysis.\n",
    "- If you encounter problems, Google first. If you can't find an answer to the problem, don't hesitate to ask in the Moodle discussion or directly via moodle chat or email from the course assistants.\n",
    "- Note! Don't leave it to the last moment! No feedback service during weekends.\n",
    "\n",
    "<font color = red size = 4><b>The deadline is 28 November at 18:00</b></font>. Late submissions will not be accepted unless there is a valid excuse for extending the deadline before the due date.\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I2WLapM3BPc"
   },
   "source": [
    "### Gather **all** packages needed for this notebook here:\n",
    "\n",
    "You can use other packages as well, but this excercise can be completed with those below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iypIAVquoDws"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning package - scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Show the plots inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "## <font color = lightcoral>1. Classification using k-nearest neighbors </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CqWZYx2oDw3"
   },
   "source": [
    "We start exploring the world of data modeling by using <font color = darkorchid><b>K-Nearest Neightbors (k-NN) algorithm</b></font>. The k-NN algorithm is one of the classic supervised machine learning algorithms. It assumes that similar points are close to each other. \n",
    "\n",
    "In our case, we'll use the k-NN algorithm to **predict the presence of cardiovascular disease** using all the other variables as <font color = darkorchid><b>features</b></font> in the given data set. So, the target variable is <font color = darkorchid><b>cardio</b></font>.\n",
    "\n",
    "But first, we need data for the task. The code for loading the data into the environment is provided for you. <font color = red>The code should work, but make sure, that you have the csv file of the data in the same directory where you have this notebook file.</font> \n",
    "\n",
    "***Exercise 1 A)*** \n",
    "\n",
    "Print the first 10 rows to check that everything is ok with the created dataframe.\n",
    "\n",
    "*note: as said, the data remains the same, but cholesterol has been one-hot-encoded for you already. There's also a new variable gluc (about glucose levels), which is one-hot-encoded for you. It has the similar values as cholesterol originally does [normal, at risk, elevated]. Also, binary variables have been changed to [0,1] values.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading code provided\n",
    "# ------------------------------------------------------\n",
    "# The data file should be at the same location than the \n",
    "# exercise file to make sure the following lines work!\n",
    "# Otherwise, fix the path.\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Path for the data\n",
    "data_path = 'ex2_cardio_data.csv'\n",
    "\n",
    "# Create a dataframe\n",
    "cardio_data = pd.read_csv(data_path, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - 10 first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfq_3_WNoDw3"
   },
   "source": [
    "----\n",
    "\n",
    "We have the data so let's make use of it. \n",
    "\n",
    "To teach the k-NN algorithm (or any kind of machine learning algorithm) to recognize patterns, we are going to need <font color = darkorchid><b>training data</b></font>. But to test how well a model possibly learned those patterns, we'll need <font color = darkorchid><b>test data</b></font> which is new and unseen for the trained model. Keep in mind that the test set is not shown for the model before we are actually done with training. \n",
    "\n",
    "So, to **find the estimate for the performance of a model**, we are going to use this <font color = darkorchid><b>train-test split</b></font>. \"Split\" because we literally split the data into two sets.\n",
    "\n",
    "Sometimes <font color = darkorchid>stratification</font> needs to be considered. It can be used to ensure that train and test sets contain the same proportions of samples of each target class as the original data set.\n",
    "\n",
    "***Exercise 1 B)*** \n",
    "\n",
    "Gather the features as an array `features`, and the target variable as an array `labels`. Produce training and test data.  Divide the data **randomly** into training (80%) and test (20%) sets.\n",
    "\n",
    "- Would it be a good idea to use stratification? **Explain** your decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daPc_o9boDw3"
   },
   "source": [
    "<font color = red> \\*** Answer here (do you need to use strafication? Explain your decision) ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "***Exercise 1 C)*** \n",
    "\n",
    "Scale the numeric features. \n",
    "\n",
    "- Remind yourself briefly why you need this step. \n",
    "- What can you say about scaling especially from the perspective of the k-NN algorithm?\n",
    "\n",
    "*tip: You should now have **two** variables where you have the features divided into. Don't forget to scale the test data. Some good information about preprocessing and how to use it for train and test data can be found https://scikit-learn.org/stable/modules/preprocessing.html.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here - why standardization? ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muqCazPIoDw4"
   },
   "source": [
    "-------\n",
    "\n",
    "It's time for us to train the model!\n",
    "\n",
    "***Exercise 1 D)*** \n",
    "\n",
    "Train a k-NN model with $k=3$. Print out the confusion matrix.\n",
    "- What can you say about the confusion matrix?\n",
    "- How does the model perform with the different classes? Where do you think the differences come from?\n",
    "- What is the total classification accuracy? How would you interpret it?\n",
    "- Perform also the following:\n",
    "    - Make 1000 **different** train and test set splits.\n",
    "    - Run the k-NN model (with $k=3$) for each split and save its accuracy.  \n",
    "    - Plot accuracies in a histogram.\n",
    "    - Discuss your results\n",
    "\n",
    "\n",
    "*tip: `sklearn.metrics.classification_report` is a great way to build up a text report showing the main classification metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NMR7Y2s6oDw4",
    "outputId": "33bd42f3-a25c-47de-cb12-908d698d08af"
   },
   "outputs": [],
   "source": [
    "### Code - kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - 1000 different train-test-splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ceztBiPoDw4"
   },
   "source": [
    "<font color = red> \\*** Answer here - Discuss your results. What can you see? What do you think is relevant? \\*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "One really common evaluation metric is <font color = darkorchid><b>the area under the receiver operating characteristic (AUROC or AUC-ROC)</b></font>.\n",
    "\n",
    "***Exercise 1 E)*** \n",
    "\n",
    "Explain what information you can learn about the one k-NN model you trained by using AUROC. Also, evaluate the performance by computing  the metric and plotting the related curve. Draw also the line for random guesses.\n",
    "\n",
    "- How would you interpret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - AUROC and ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here - Explain the results ***  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQfehqAioDw4"
   },
   "source": [
    "__________\n",
    "## <font color = royalblue> 2. Classification accuracy using leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPZx-6JLoDw5"
   },
   "source": [
    "Even thought the train-test split gives us an unbiased estimate of the performance, we only evaluate the model one time. Especially with very small data sets, a test set will be very small. How can we be sure that the evaluation is accurate with this small test set and not just a good (or bad) luck? And what if we'd like to compare two models and the other seems to be better -- how can we be sure that it's not just a coincidence?\n",
    "\n",
    "Well, there's a great help available and it's called <font color = darkorchid><b>cross-validation</b></font>. This time, we'll take a look at <font color = darkorchid><i>leave-one-out cross-validation</i></font>.\n",
    "\n",
    "***Exercise 2 A)***\n",
    "\n",
    "Describe *in your own words*, how leave-one-out cross validation works? How does it actually differ from the basic train-test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXJmJ80DoDw5"
   },
   "source": [
    "<font color = red> \\*** Answer here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "***Exercise 2 B)***\n",
    "\n",
    "Let's predict once again the **presence of cardiovascular disease** using all the other variables in the dataset as features. Now, use leave-one-out cross validation to estimate the model performance. Again, use a kNN classifier with $k=3$.\n",
    "\n",
    "- What is the classification accuracy? Compare the result with the one you got in the previous task.\n",
    "\n",
    "*tip: Sure this could be done manually, but `cross_val_score` is quite a handy function too.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "znHjVwKDoDw5",
    "outputId": "3b73cc4a-eef7-4e9e-be17-19d79df71033",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Code - Leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88BjCQL6oDw5"
   },
   "source": [
    "____________\n",
    "## <font color = forestgreen> 3. Model selection with leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8fcES_LoDw5"
   },
   "source": [
    "So far, we've trained one model at a time and I've given the value of k for you. Accuracy is what it is (no spoilers here), but could we still do a little better? Let's try that by <font color = darkorchid><b>hyperparameter tuning</b></font>.\n",
    "\n",
    "This time, we're going to train multiple models, let's say 30, and choose the best K-Nearest Neighbors model among the others. Almost all models have some parameters that need to be chosen. As does the k-NN, I just happened to choose the k value of 3 for you. Note, k-NN has many other hyperparameters too, but for the sake of simplicity, this time we'll focus only on the nearest neighbors. \n",
    "\n",
    "Now, you're supposed to find that *optimal value* for k.\n",
    "\n",
    "***Exercise 3***\n",
    "\n",
    "Repeat the model performance estimation with values $k=1...30$ using again leave-one-out cross validation.\n",
    "\n",
    "- Which value of k produces the best classification accuracy?\n",
    "- If the number of k is still increased, what is the limit that the classification accuracy approaches? Why? \n",
    "- Can you say something about the performance of this selected model with new, unseen data? Explain, how you could you estimate the performance of this selected model.\n",
    "\n",
    "*tip: `GridSearchCV` is a good class for this but will you get the other but the best k value out of it?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RJ7570_ZoDw6",
    "outputId": "91caaf74-2636-46f7-a4e3-4e5ba98e4c4e"
   },
   "outputs": [],
   "source": [
    "### Code - Select best k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9r2v1LEDoDw6"
   },
   "source": [
    "________________\n",
    "## <font color = red>  4. Testing with training data <font color = red> (this should *never* be done out of this exercise!) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6B6L5HWoDw6"
   },
   "source": [
    "Oh, but what if we just used the ***whole data*** in training? Wouldn't we like to use as much data as possible to discover the underlying pattern in the data so why **not** to use the whole data?\n",
    "\n",
    "*Never ever* do this out of this exercise. Why? Let's take a look.\n",
    "\n",
    "***Exercise 4***\n",
    "\n",
    "Repeat the previous task but use the whole data for training. Plot the resulting classification accuracy versus $k = 1...30$. Include the values from the previous task in the *same figure*.\n",
    "\n",
    "- Comment your result and answer, why you should not test with training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ExWjmjQ5oDw6",
    "outputId": "f7bd8eac-a636-400b-a8a4-9ca269129628",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Code - Train with whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color = red> \\*** Answer here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________\n",
    "\n",
    "## <font color = darkorange> 5. Comparison of ridge regression and kNN regression </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous exercises were about classification. Now, we are ready to see another kind of supervised learning - regression. We're going to use <font color = darkorchid><b>Ridge Regression</b></font> and <font color = darkorchid><b>K-Nearest Neighbors Regression</b></font>, and compare the performances of these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this exercise more intuitively, let's change the data to another somewhat famous dataset called *The Boston Housing Dataset*. The Boston Housing Dataset is a derived from information collected by the U.S. Census Service concerning housing in the area of Boston, Massachusetts. Let's have a quick peek at the variables:\n",
    "\n",
    "- **CRIM** - per capita crime rate by town\n",
    "- **ZN** - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- **INDUS** - proportion of non-retail business acres per town.\n",
    "- **CHAS** - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- **NOX** - nitric oxides concentration (parts per 10 million)\n",
    "- **RM** - average number of rooms per dwelling\n",
    "- **AGE** - proportion of owner-occupied units built prior to 1940\n",
    "- **DIS** - weighted distances to five Boston employment centres\n",
    "- **RAD** - index of accessibility to radial highways\n",
    "- **TAX** - full-value property-tax rate per \\$10,000\n",
    "- **PTRATIO** - pupil-teacher ratio by town\n",
    "- **B** - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- **LSTAT** - % lower status of the population\n",
    "- **MEDV** - Median value of owner-occupied homes in \\$1000's\n",
    "\n",
    "\n",
    "No worries if the variables don't make a lot of sense. However, the object is to predict **the median house value**. So the target variable is now <font color = darkorchid><b>MEDV</b></font> and all the others are <font color = darkorchid><b>features</b></font>.\n",
    "\n",
    "There's the code chunk for loading data provided again. <font color = red>Again, the data file should be located in the same directory as this notebook file!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading code provided\n",
    "# ------------------------------------------------------\n",
    "# The data file should be at the same location than the \n",
    "# exercise file to make sure the following lines work!\n",
    "# Otherwise, fix the path.\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Data path\n",
    "data_path = 'ex2_boston_housing_data.csv'\n",
    "\n",
    "# Load the data \n",
    "boston_data = pd.read_csv(data_path, dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "With regression, we can examine **the relationship between two or more variables**. This relationship is represented by an *equation*, which itself represents how much y changes with any given change of x. So for example, we could use *age* as an independent variable to predict *height* (a dependent variable). \n",
    "\n",
    "We start by looking at the relationships between the variables in the given dataset.\n",
    "\n",
    "\n",
    "***Exercise 5 A)***\n",
    "\n",
    "Make scatter plots where you present each feature versus the target variable `MEDV`.\n",
    "\n",
    "- What can you say about the relationships?\n",
    "\n",
    "*tip: seaborn.pairplot is quite a handy function where you can set x_vars and y_vars to point out the variables you need*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Code - Scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red>\\*** Answer here - the relationships *** </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "We are about to compare two different regression models. We need to be sure that both are *the best models* among the other trained models. But to make sure that these selected models really are the best ones, we're going to use a combination of cross-validation and hyperparameter tuning right away. What's the other way to ensure that the chosen hyperparameters are appropriate for the given data?\n",
    "\n",
    "For the k-Nearest neighbors, we have previously get familiar with the optimization of the k value. Let's continue with this value to find the *optimal k* for the k-nearest neighbors regression too. With ridge regression, we have this hyperparameter called $\\lambda$ (read as 'lambda'). We'll use this parameter for model selection.\n",
    "\n",
    "\n",
    "To compare the models, let's use a loss function called <font color = darkorchid><b>mean absolute error (MAE)</b></font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "***Exercise 5 B)***\n",
    "\n",
    "Do you need to prepare the data a little? Explain your decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red>\\*** Answer here *** </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "***Exercise 5 C)***\n",
    "\n",
    "Then, train a ridge regression model  and a k-NN regression model. For hyperparameters, use $\\lambda=2^{-10}...2^{10}$ and $k=1...30$. Once again, use leave-one-out cross validation.\n",
    "\n",
    "- What are the total performances of each model and how they compare with each other? \n",
    "- What does the MAE tell you about the performances of your models and in general?\n",
    "\n",
    "*note: In a `sklearn.linear_model.Ridge` class, lambda is called alpha so don't get confused*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Ridge regression and k-NN regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red>\\*** Answer here - discuss your results (comparison and MAE) ***</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "We can say something about the performance now. One way to do the visualization is to plot actual labels vs predicted labels. Let's do that.\n",
    "\n",
    "\n",
    "***Exercise 5 D)***\n",
    "\n",
    "Using the best models found in the previous exercise, plot the actual labels vs. predicted labels. \n",
    "\n",
    "- How did the selected models perform?\n",
    "- In an ideal situation, where should the data points be located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - Plot actual vs predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________\n",
    "## <font color = dimgrey> BONUS: Feature selection - most useful features in predicting the disease </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stop here and get the \"pass\" grade! To get the \"pass with honors\" grade, you need to do the following exercise. This means you'll get one bonus point for the exam.\n",
    "\n",
    "The exercise is not as straightforward as the previous ones, and may require you to do some research of your own. You are also required to **explain** the steps you choose with your own words, and show that you tried to understand the idea behind the task. There's no single correct solution for this so just explain me what you did and why you did it.\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "Unfortunately, due to the lack of resources and time, doctors are not able to measure all the values represented in the given dataset. Luckily, keen students are ready to help: You should now find <font color = darkorchid><b>five [5] most useful features</b></font> in predicting the presence of the cardiovascular disease among the ones in the given cardio data set. \n",
    "\n",
    "Use the selected features to train and test a model of your choice. Evaluate the performance by computing the accuracy and drawing a ROC curve. Remember not to use any information from the test set when selecting the features!\n",
    "\n",
    "**Discuss** your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code - BONUS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \\*** Answer here *** </font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DADK2020_ex3_Valtteri_Nieminen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "180px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
